{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../assets/tumor_twin.png\" alt=\"Tumor Twin\" width=\"500\"/>\n",
    "\n",
    "# Triple negative breast cancer (TNBC) Demo\n",
    "This demo showcases an end-to-end image-guided digital twin workflow with `TumorTwin`.\n",
    "\n",
    "---\n",
    "## ðŸ“š Table of Contents\n",
    "- [Step 1: Data Loading](#step-1-data-loading-and-preprocessing)\n",
    "- [Step 2: Create Tumor Growth Model](#step-2-create-tumor-growth-model)\n",
    "- [Step 3: Create a Solver object](#step-3-create-a-solver-object)\n",
    "- [Step 4: Make a prediction](#step-4-make-a-prediction)\n",
    "- [Step 5 (Optional): Compute a quantity of interest and its gradient](#step-5-optional-compute-a-quantity-of-interest-and-its-gradient)\n",
    "- [Step 6: Compare the model prediction to patient data](#step-6-compare-the-model-prediction-to-patient-data)\n",
    "- [Step 7: Calibrate the model to patient data via numerical optimization](#step-7-calibrate-the-model-to-patient-data-via-numerical-optimization)\n",
    "- [Step 8: Predict patient response under alternative treatment plan](#step-8-predict-patient-response-under-alternative-treatment-plan)\n",
    "- [Conclusion & Discussion questions](#conclusion--discussion-questions)\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T13:11:56.373559Z",
     "start_time": "2025-04-10T13:11:46.639770Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "## Imports...\n",
    "import os\n",
    "from datetime import timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import FilePath\n",
    "from rich import print\n",
    "\n",
    "from tumortwin.models import ReactionDiffusion3D\n",
    "from tumortwin.optimizers import LMoptimizer, LMoptions\n",
    "from tumortwin.postprocessing import (\n",
    "    compute_total_cell_count,\n",
    "    plot_calibration,\n",
    "    plot_calibration_iter,\n",
    "    plot_cellularity_map,\n",
    "    plot_imaging_summary,\n",
    "    plot_loss,\n",
    "    plot_maps_final,\n",
    "    plot_measured_TCC,\n",
    "    plot_patient_timeline,\n",
    "    plot_predicted_TCC,\n",
    ")\n",
    "from tumortwin.preprocessing import ADC_to_cellularity, compute_carrying_capacity\n",
    "from tumortwin.solvers import TorchDiffEqSolver, TorchDiffEqSolverOptions\n",
    "from tumortwin.types import (\n",
    "    ChemotherapySpecification,\n",
    "    CropSettings,\n",
    "    CropTarget,\n",
    "    TNBCPatientData,\n",
    ")\n",
    "from tumortwin.utils import daterange, days_since_first\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "%matplotlib inline\n",
    "font = {\n",
    "    \"weight\": \"normal\",\n",
    "    \"size\": 10,\n",
    "}\n",
    "matplotlib.rc(\"font\", **font)\n",
    "matplotlib.rc(\"figure\", dpi=300)\n",
    "matplotlib.rc(\"savefig\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Data Loading\n",
    "### Create PatientData object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load in the input dataset. You will need to ensure that the relevant input filepaths are set correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T13:12:26.072852Z",
     "start_time": "2025-04-10T13:12:26.070157Z"
    }
   },
   "outputs": [],
   "source": [
    "PATIENT_INFO_PATH = FilePath(\"../input_files/TNBC_demo_001/TNBC_demo_001.json\")\n",
    "IMAGE_PATH = FilePath(\"../input_files/TNBC_demo_001\")\n",
    "crop_settings = CropSettings(crop_to=CropTarget.ROI_ENHANCE, padding=10, visit_index=-1)\n",
    "patient_data = TNBCPatientData.from_file(\n",
    "    PATIENT_INFO_PATH, image_dir=IMAGE_PATH, crop_settings=crop_settings\n",
    ")\n",
    "measured_cellularity_maps = [\n",
    "    ADC_to_cellularity(\n",
    "        visit.adc_image, visit.roi_enhance_image\n",
    "    )\n",
    "    for visit in patient_data.visits\n",
    "]\n",
    "k = torch.tensor(0.025, requires_grad=True, device=device)\n",
    "d = torch.tensor(0.05, requires_grad=True, device=device)\n",
    "theta = torch.tensor(1.0, requires_grad=False, device=device)\n",
    "ct = ChemotherapySpecification(\n",
    "    sensitivity=0.2,\n",
    "    decay_rate=0.7,\n",
    "    times=[c.time for c in patient_data.chemotherapy],\n",
    "    doses=[c.dose for c in patient_data.chemotherapy],\n",
    ")\n",
    "# print(ct)\n",
    "model = ReactionDiffusion3D(\n",
    "    k=k,\n",
    "    d=d,\n",
    "    theta=theta,\n",
    "    patient_data=patient_data,\n",
    "    initial_time=patient_data.visits[0].time,\n",
    "    chemotherapy_specifications=[ct],\n",
    "    radiotherapy_specification=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Create a Solver object\n",
    "Under the hood, our `ReactionDiffusion3D` model is actually a spatially discretized version of the reaction-diffusion PDE. Solving this semi-discrete model requires solving a large system of ordinary differential equations (ODEs). We do this via the `torchdiffeq` library, using the `TorchDiffEqSolver` object.\n",
    "\n",
    "The `TorchDiffEqSolverOptions` object contains standard solver options such as the method to use (e.g. fourth-order Runge-Kutta or \"rk4\"), the timestep to use for solving, and whether to use the adjoint method for gradient computations (`False` would resort to automatic differentiation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T13:12:31.342276Z",
     "start_time": "2025-04-10T13:12:31.340392Z"
    }
   },
   "outputs": [],
   "source": [
    "solver_options = TorchDiffEqSolverOptions(\n",
    "    step_size=timedelta(days=0.5),\n",
    "    use_adjoint=True,\n",
    "    device=device,\n",
    "    method=\"rk4\",\n",
    ")\n",
    "\n",
    "solver = TorchDiffEqSolver(model, solver_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Make a prediction\n",
    "We are now ready to leverage our model and solver to make a prediction of tumor growth and response to treatment.\n",
    "\n",
    "We will use the measured cellularity map from the first patient visit (`measured_cellularity_maps[0]`) as an initial condition for the model, and make a prediction from the first visit date until the final visit date: a total of `119 days`. We will output the solution every `0.5 days`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T13:12:51.812655Z",
     "start_time": "2025-04-10T13:12:32.912295Z"
    }
   },
   "outputs": [],
   "source": [
    "timepoints = daterange(\n",
    "    patient_data.visits[0].time, patient_data.visits[-1].time, timedelta(days=0.5)\n",
    ")\n",
    "u0 = torch.from_numpy(measured_cellularity_maps[0].array)\n",
    "\n",
    "# times, predicted_cellularity_maps = solver.solve(timepoints=timepoints, u_initial=u0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 7: Calibrate the model to patient data via numerical optimization\n",
    "Rather than a trial-and-error approach, we can instead leverage numerical optimization to calibrate our model parameters to better match the observed data.\n",
    "\n",
    "We will use the Levenberg-Marquardt (LM) algorithm ([Wikipedia Link](https://en.wikipedia.org/wiki/Levenbergâ€“Marquardt_algorithm)). This algorithm will seek to minimize the sum-of-squares difference between our predicted cellularity fields and the measured cellularity fields., i.e.,\n",
    "\n",
    "$$\n",
    "\\sum_{v=0}^{\\texttt{N\\_visits}} \\sum_{j=0}^{\\texttt{N\\_voxels}} (N_j(t_v) - \\hat{N}_j(t_v))^2\n",
    "$$\n",
    "where $t_v$ is the time step corresponding to visit $v$, $N_j$ and $\\hat{N}_j$ are the discretized predicted and measured (respectively) cellularity values at voxel $j$.\n",
    "\n",
    "First we choose how many imaging visits to calibrate to by setting `n_calibration_targets`, and picking out the corresponding solutions and timepoints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T13:18:51.853844Z",
     "start_time": "2025-04-10T13:18:51.850627Z"
    }
   },
   "outputs": [],
   "source": [
    "# How many imaging dates do we want to try and match\n",
    "n_visits_calibration = 2 # *Including* the initial visit\n",
    "\n",
    "target_timepoints = [visit.time for visit in patient_data.visits[:n_visits_calibration]]\n",
    "target_solution = torch.stack(\n",
    "    tuple(\n",
    "        [\n",
    "            torch.from_numpy(m.array)\n",
    "            for m in measured_cellularity_maps[: n_visits_calibration]\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create a helper function for the optimizer. This function simply takes a set of parameter values, updates the model with these parameter values, runs a forward solve, and outputs the solution at the target timepoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T13:34:07.598292Z",
     "start_time": "2025-04-10T13:23:17.803984Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Optimization Step: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Optimization Step: \u001b[1;36m1\u001b[0m/\u001b[1;36m1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb42eab658242e6a495d4fc568f7d7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Forward Simulation: [2001-09-14 00:00:00 to 2001-11-10 00:00:00 with timestep 0.50 days]:   0%|          | 0.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing jacobians at initial point\n",
      "self.x requires grad?\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6020aec31442461ca976607874e20ebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Forward Simulation: [2001-09-14 00:00:00 to 2001-11-10 00:00:00 with timestep 0.50 days]:   0%|          | 0.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.grad is None? False\n",
      "Parameter containing:\n",
      "tensor(0.0500, requires_grad=True)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'TorchDiffEqSolver' object has no attribute 'k'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_iter):\n\u001b[32m     32\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mOptimization Step: \u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(i+\u001b[32m1\u001b[39m) +\u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m+\u001b[38;5;28mstr\u001b[39m(n_iter))\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     \u001b[43moptim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m best_parameters = optim.parameters[-\u001b[32m1\u001b[39m]\n\u001b[32m     36\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest parameters: \u001b[39m\u001b[33m\"\u001b[39m, best_parameters)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/tumortwin/tumortwin/optimizers/lm_optimizer.py:154\u001b[39m, in \u001b[36mLMoptimizer.step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._n_iters == \u001b[32m0\u001b[39m:\n\u001b[32m    153\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mInitial step\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_initialize_first_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._accepted_step:\n\u001b[32m    156\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAccepted step\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:9\u001b[39m, in \u001b[36m_initialize_first_iteration\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:19\u001b[39m, in \u001b[36m_get_jacobian_torch\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[31mAttributeError\u001b[39m: 'TorchDiffEqSolver' object has no attribute 'k'"
     ]
    }
   ],
   "source": [
    "# from functorch import make_functional\n",
    "# fmodel, params = make_functional(solver.model)\n",
    "\n",
    "# def model(model_parameters):\n",
    "#     solve.model = fmodel.bind(model_pa)\n",
    "#     d, k, ct_sens = model_parameters\n",
    "#     solver.model.d = torch.nn.Parameter(d)\n",
    "#     solver.model.k = torch.nn.Parameter(k)\n",
    "#     solver.model.chemotherapy_specifications[0].sensitivity = torch.nn.Parameter(ct_sens)\n",
    "#     _, predicted_cellularity_maps = solver.solve(timepoints=timepoints, u_initial=u0)\n",
    "#     return predicted_cellularity_maps\n",
    "\n",
    "# def predict(timepoints = target_timepoints):\n",
    "\n",
    "# initial guess for the optimizer - here we use the values currently stored in the model\n",
    "# initial_parameters = torch.tensor((solver.model.d, solver.model.k, solver.model.radiotherapy_specification.alpha, solver.model.chemotherapy_specifications[0].sensitivity))\n",
    "initial_parameters = torch.tensor((0.025, 0.05, 0.5))\n",
    "options = LMoptions()\n",
    "optim = LMoptimizer(\n",
    "    solver=solver,\n",
    "    timepoints = target_timepoints,\n",
    "    u0 = u0,\n",
    "    initial_guess=initial_parameters,\n",
    "    bounds=torch.tensor(((0.0, 2), (0.0, 0.5), (0.0, 1.0))),\n",
    "    y_data=target_solution,\n",
    "    options=options,\n",
    ")\n",
    "# Run optimization for n_iter steps\n",
    "n_iter = 1\n",
    "\n",
    "for i in range(n_iter):\n",
    "    print(\"Optimization Step: \" + str(i+1) +\"/\"+str(n_iter))\n",
    "    optim.step()\n",
    "\n",
    "best_parameters = optim.parameters[-1]\n",
    "print(\"Best parameters: \", best_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the optimization iterations\n",
    "Let's visualize the progress of the optimizer by visualizing solutions at every `n_opt_viz` optimization steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T13:39:53.500311Z",
     "start_time": "2025-04-10T13:36:15.126182Z"
    }
   },
   "outputs": [],
   "source": [
    "n_opt_viz = 2\n",
    "sols = []\n",
    "for params in optim.parameters[::n_opt_viz]:\n",
    "    predicted_cellularity_maps = update_model_and_predict(params, timepoints)\n",
    "    sols.append(predicted_cellularity_maps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we plot the solutions visited by the optimizer, along with the corresponding loss (sum-of-squares error) values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T13:39:57.283176Z",
     "start_time": "2025-04-10T13:39:53.501399Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax =plt.subplots(1,1, figsize=(5,2))\n",
    "plot_calibration_iter(\n",
    "    sols, carrying_capacity, timepoints, measured_cellularity_maps, patient_data, t_calibration_end=target_timepoints[-1], ax=ax\n",
    ")\n",
    "\n",
    "fig, ax =plt.subplots(1,1, figsize=(5,2))\n",
    "plot_loss(torch.tensor(optim.error), ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this particular dataset, we know what the ground-truth parameter values are since we used them to generate the data! Of course, in a real scenario you wouldn't know what the \"true\" parameters are. In fact, the data might not exactly match the model for _any_ value of the parameters.\n",
    "\n",
    "Ideally, our calibrated parameter values will be close to these, so let's compute the relative error in each parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T13:39:57.294018Z",
     "start_time": "2025-04-10T13:39:57.283950Z"
    }
   },
   "outputs": [],
   "source": [
    "true_parameters = torch.tensor((0.1,0.05, 0.2))\n",
    "final_parameters = optim.parameters[-1]\n",
    "\n",
    "\n",
    "def relative_error_2dp(estimate, truth):\n",
    "    return (100*abs(truth-estimate)/truth).round(decimals=2)\n",
    "\n",
    "\n",
    "print(f\"Error in d: {relative_error_2dp(final_parameters[0], true_parameters[0])}%\")\n",
    "print(f\"Error in k: {relative_error_2dp(final_parameters[1], true_parameters[1])}%\")\n",
    "print(f\"Error in ct_sens: {relative_error_2dp(final_parameters[2], true_parameters[2])}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Predict patient response under alternative treatment plan\n",
    "Now that we have a calibrated digital twin model, we can use it to predict how this particular patient might respond to different treatment plans.\n",
    "\n",
    "Recall that we calibrated the digital twin model to imaging visits acquired after _four weeks of neoadjuvant chemotherapy_. A remaining treatment decision might be the neoadjuvant chemotherapy dosages and schedule. We would expect that increasing the dosage will lead to greater tumor control, but note that higher dosages are also likely to lead to greater toxicity. Let's explore the tradeoff using our calibrated digital twin model!\n",
    "\n",
    "First, we'll define a function that updates the remaining chemotherapy doses based on a given *total* chemotherapy dosage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T13:41:08.984410Z",
     "start_time": "2025-04-10T13:41:08.982172Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_ct_total_dose(ct : ChemotherapySpecification, total_dose : float):\n",
    "    current_total_dose : float = np.sum(np.array(ct.doses))\n",
    "    additional_dose = total_dose - current_total_dose\n",
    "\n",
    "    adjuvant_total_dose = np.sum(ct.doses[4:])\n",
    "    dose_multiplier = (additional_dose+adjuvant_total_dose) / adjuvant_total_dose\n",
    "    ct.doses[4:] = [d*dose_multiplier for d in ct.doses[4:]]\n",
    "    return ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's predict the tumor response for a range of total dosages, and plot the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T13:45:16.427872Z",
     "start_time": "2025-04-10T13:43:54.728212Z"
    }
   },
   "outputs": [],
   "source": [
    "sols = []\n",
    "candidate_doses = [20,30, 40, 50, 60]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 2))\n",
    "for ct_total_dose in candidate_doses:\n",
    "    update_ct_total_dose(ct, ct_total_dose)\n",
    "    solver.model.chemotherapy_specifications = [ct]\n",
    "    print(f\"Running forward solve with total dose = {ct_total_dose}\")\n",
    "    times, predicted_cellularity_maps = solver.solve(timepoints=timepoints, u_initial=u0)\n",
    "    plot_predicted_TCC(predicted_cellularity_maps, timepoints, ax=ax, alpha= 0.25 + 0.75*(ct_total_dose-min(candidate_doses))/(max(candidate_doses)-min(candidate_doses)))\n",
    "\n",
    "ax.legend([\"Total dose: \"+str(d) for d in candidate_doses]);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion \n",
    "Here we have demonstrated the core workflows of `TumorTwin`. We have shown how to load in a patient dataset, create a tumor growth model, create a solver for the model, make predictions with the model under various parameters and treatments, and calibrate the model to patient data.\n",
    "\n",
    "## Discussion Questions\n",
    "__Modeling__\n",
    "- What effects could we add to the reaction-diffusion model?\n",
    "\n",
    "__Calibration__\n",
    "- How much data is needed for calibration?\n",
    "- How does the timing of the imaging visits influence the calibration performance?\n",
    "- Under what conditions might the calibration be unable to uniquely identify all the parameters?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
